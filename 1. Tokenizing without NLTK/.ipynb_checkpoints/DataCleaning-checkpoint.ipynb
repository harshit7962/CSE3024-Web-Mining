{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading input from a text file and saving it as a string\n",
    "text = \"\"\n",
    "with open('test_file.txt') as file:\n",
    "    for line in file:\n",
    "        for word in line.split():  \n",
    "            text= text + \" \" + word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hello world this subject is cse3024 web mining in g2 slot i am harshit mishra and my registration number is 19bce0799 i am a third year undergraduate student at vellore institute of technology vellore this is a test file for tokenizing words in python without using inbuilt libraries'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuations from our input file\n",
    "import re\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world', 'this', 'subject', 'is', 'cse3024', 'web', 'mining', 'in', 'g2', 'slot', 'i', 'am', 'harshit', 'mishra', 'and', 'my', 'registration', 'number', 'is', '19bce0799', 'i', 'am', 'a', 'third', 'year', 'undergraduate', 'student', 'at', 'vellore', 'institute', 'of', 'technology', 'vellore', 'this', 'is', 'a', 'test', 'file', 'for', 'tokenizing', 'words', 'in', 'python', 'without', 'using', 'inbuilt', 'libraries']\n"
     ]
    }
   ],
   "source": [
    "#Printing each token\n",
    "tokens = text.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19bce0799' 'a' 'am' 'and' 'at' 'cse3024' 'file' 'for' 'g2' 'harshit'\n",
      " 'hello' 'i' 'in' 'inbuilt' 'institute' 'is' 'libraries' 'mining' 'mishra'\n",
      " 'my' 'number' 'of' 'python' 'registration' 'slot' 'student' 'subject'\n",
      " 'technology' 'test' 'third' 'this' 'tokenizing' 'undergraduate' 'using'\n",
      " 'vellore' 'web' 'without' 'words' 'world' 'year']\n"
     ]
    }
   ],
   "source": [
    "#Printing unique tokens\n",
    "import numpy as np\n",
    "tokens = np.unique(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing StopWords\n",
    "stopwords = [\"i\", \"a\", \"am\", \"and\", \"at\", \"for\", \"in\", \"is\", \"my\", \"of\", \"this\"]\n",
    "res = []\n",
    "for x in tokens:\n",
    "    if x not in stopwords:\n",
    "        res.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19bce0799', 'cse3024', 'file', 'g2', 'harshit', 'hello', 'inbuilt', 'institute', 'libraries', 'mining', 'mishra', 'number', 'python', 'registration', 'slot', 'student', 'subject', 'technology', 'test', 'third', 'tokenizing', 'undergraduate', 'using', 'vellore', 'web', 'without', 'words', 'world', 'year']\n"
     ]
    }
   ],
   "source": [
    "#Printing cleaned tokens in our input text file\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
